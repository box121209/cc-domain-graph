{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN model of URIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check that Tensorflow is correctly installed and can see the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16683986875084193420\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the pre-amble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, Recurrent\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import gzip\n",
    "import math\n",
    "\n",
    "def entropy(pred): \n",
    "    return sum([-p*math.log(p) for p in pred])\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Samples an index from a probability array;\n",
    "    higher temperature raises the entropy and vice versa    \n",
    "    \"\"\"\n",
    "    a = np.log(a) / temperature\n",
    "    dist = np.exp(a) / np.sum(np.exp(a))\n",
    "    choices = range(len(a)) \n",
    "    return np.random.choice(choices, p=dist)\n",
    "\n",
    "def hx(i):\n",
    "    \"\"\"\n",
    "    Normalised 2-char hex representation of 0-255\n",
    "    \"\"\"\n",
    "    a = hex(i)[2:]\n",
    "    if len(a)<2: a = ''.join(['0',a])\n",
    "    return a\n",
    "\n",
    "hexabet = [hx(x) for x in range(256)]\n",
    "byte_idx = dict((c, i) for i, c in enumerate(hexabet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the domain string file for training. At present from cloned git repo. \n",
    "\n",
    "TO DO: read from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# bytes: 10000\n",
      "\n",
      "\n",
      "/www868686.wyw.cn/ncontact_346701.html\n",
      "/wlrq.wyw.cn/tradelist_347993.html\n",
      "/BANTAI801.wyw.cn/ntrade_541599.html\n",
      "/bantai806.wyw.cn/ncontact_541502.html\n",
      "/www.snc.edu/assets2/images/socialmedia/insta.png\n",
      "/page-4403.html\n",
      "/goodlife.wyw.cn/tradelist_540770.html\n",
      "/www.snc.edu/assets2//images/socialmedia/face.png\n",
      "/C:/Users/Skipper/Google%20%E9%9B%B2%E7%AB%AF%E7%A1%AC%E7%A2%9F/%E8%BB%8D%E4%BA%8B%E5%BE%AE%E9%9D%A9%E5%91%BD/%E8%87%AA%E8%A3%BD%E6%BD%9B%E8%89%A6%E6%98%AF%E4%B8%80%E9%A0%85%E5%BF%85%E9%A0%88%E5%84%98%E6%97%A9%E8%90%BD%E5%AF%A6%E7%9A%84%E5%9C%8B%E5%AE%B6%E9%87%8D%E5%A4%A7%E6%94%BF%E7%AD%96.docx\n",
      "/www.snc.edu/assets3/images/saint.png\n",
      "/www.xe.com/es/currencycharts/\n",
      "/page-843.html\n",
      "/page-1568.html\n",
      "/page-2924.html\n",
      "/piwik.php\n",
      "/wlkcjj.wyw.cn/contact_352711.html\n",
      "/DIMA.wyw.cn/tradelist_350616.html\n",
      "/www.abc7.com/apps\n",
      "/page-59.html\n",
      "/page-5792.html\n",
      "/BANTAI801.wyw.cn/ncontact_541599.html\n",
      "/joyson.ru/\n",
      "/newpearl.wyw.cn/contact_353014.html\n",
      "/page-6947.html\n",
      "/summit.wyw.cn/contact_347098.html\n",
      "/C:/Users/dm\n"
     ]
    }
   ],
   "source": [
    "train_file = \"smallstring.gz\"\n",
    "path = \"../sdata/\"\n",
    "\n",
    "with gzip.open(path + train_file, 'rb') as f:\n",
    "    content = f.read()\n",
    "\n",
    "#bytes = [b.encode('hex') for b in content][int(3e07):int(4e07)] #Â sample bytes for local testing\n",
    "bytes = [b.encode('hex') for b in content]\n",
    "print('# bytes:', len(bytes))\n",
    "print(content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and test strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training length: 7500\n",
      "test length: 2500\n"
     ]
    }
   ],
   "source": [
    "# divide into training and test sets:\n",
    "n_train = int(3*len(bytes)/4)\n",
    "text_train = bytes[0:n_train]\n",
    "text_test = bytes[n_train:len(bytes)]\n",
    "\n",
    "print('training length:', len(text_train))\n",
    "print('test length:', len(text_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut the text in semi-redundant 'sentences' of bytes, each of length <tt>unroll</tt>, and stepping forward a number <tt>step</tt> of bytes each time. \n",
    "\n",
    "These sentences are then converted into numpy arrays for RNN input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sequences: 2494\n"
     ]
    }
   ],
   "source": [
    "unroll = 20\n",
    "step = 3\n",
    "sentences = []\n",
    "next_byte = []\n",
    "for i in range(0, n_train - unroll, step):\n",
    "    sentences.append(text_train[i: i + unroll])\n",
    "    next_byte.append(text_train[i + unroll])\n",
    "print('# sequences:', len(sentences))\n",
    "\n",
    "# convert to feature vector + next character:\n",
    "X = np.zeros((len(sentences), unroll, 256), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), 256), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t,b in enumerate(sentence):\n",
    "        X[i, t, byte_idx[b]] = 1\n",
    "    y[i, byte_idx[next_byte[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the RNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 16)                17472     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 21,824\n",
      "Trainable params: 21,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model: 2 stacked LSTM\n",
    "\n",
    "nhidden = [16] # e.g. [512, 512]\n",
    "dropout = 0.1\n",
    "nlayers = len(nhidden)\n",
    "INSIZE = 256\n",
    "OUTSIZE = 256\n",
    "\n",
    "model = Sequential()\n",
    "if nlayers > 1:\n",
    "    for i in range(nlayers-1):\n",
    "        model.add(LSTM(nhidden[i],\n",
    "                       return_sequences=True,\n",
    "                       input_shape=(unroll, INSIZE)))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(LSTM(nhidden[nlayers-1],\n",
    "                   return_sequences=False))\n",
    "else:\n",
    "    model.add(LSTM(nhidden[0],\n",
    "                   return_sequences=False,\n",
    "                   input_shape=(unroll, INSIZE)))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(OUTSIZE))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load existing weights into the model, or fit from random initialisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# either load weights:\n",
    "wt_path = \"../models/\"\n",
    "model.set_weights(np.load(wt_path+\"model_from_big_domain_string_1.gz_arch_256_16_unroll_20_step_3_dropout_0.1.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4999994/4999994 [==============================] - 1304s - loss: 2.6086  - ETA: 0s -\n",
      "Epoch 2/20\n",
      "4999994/4999994 [==============================] - 1301s - loss: 2.5842  - ETA: 0s - loss: 2.584\n",
      "Epoch 3/20\n",
      "4999994/4999994 [==============================] - 1301s - loss: 2.5756  \n",
      "Epoch 4/20\n",
      "4999994/4999994 [==============================] - 1331s - loss: 2.5701  \n",
      "Epoch 5/20\n",
      "4999994/4999994 [==============================] - 1295s - loss: 2.5671  \n",
      "Epoch 6/20\n",
      "4999994/4999994 [==============================] - 1293s - loss: 2.5645  \n",
      "Epoch 7/20\n",
      "4999994/4999994 [==============================] - 1292s - loss: 2.5615  \n",
      "Epoch 8/20\n",
      "1983104/4999994 [==========>...................] - ETA: 780s - loss: 2.5604"
     ]
    }
   ],
   "source": [
    "# or fit and save weights:\n",
    "wt_path = \"../sdata/\"\n",
    "wt_file = \"model_from_%s_arch\" % train_file\n",
    "for i in nhidden: \n",
    "    wt_file += \"_%d\" % i\n",
    "wt_file += \"_unroll_%d_step_%d_dropout_%g.npy\" % (unroll, step, dropout)\n",
    "\n",
    "model.fit(X, y, batch_size=128, epochs=20, verbose=1)\n",
    "np.save(wt_path + wt_file, model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeball the model by using it to generate a stretch of synthetic domain strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------------------\n",
      "Seed:\n",
      "s/Windows-Network-St\n",
      " --------------------------------------------------\n",
      "s/Windows-Network-Stren-mnnatonen-coeker-1cab713/imaaters/huri/wwAve-me-veet-dese/\n",
      "/4810nd-atere_3084202046.jpc/Qlg,aeil-eorchen/\n",
      "/untoonglo/miss16.nobuleberlameeaalanfstor-cortiit-ked/5545/114824915/2_/T061D17117477\n",
      "/Seu-735-MolluCmlauting/cansic/1200_216/-insor_e-/uiu\n",
      "/firsi_spustics\n",
      "/2011/\n",
      "/fancers/spenarl-killiom45--AlcFaet/llcvelmo_%D9%82%D8%AF%D8\n",
      "//Teuldel_U_YBGIileLrUEodgx235024103i-gI97Mn48/10/Veitomsg5z01559679A\n",
      "/chepbued/amerprorwors/upris-vidIgo3-kodcbelenuar_.com\n",
      "/p.tmg\n",
      "/es/SSc75d271627_misssr.com/\n",
      "/e013366daunfcbatal-oatize-lia-bid-hennn-50207.fs\n",
      "/rtvtes-cant-wate\n",
      "/wst.1/20A3nmacir/nern-taacy-sybinnitore/kobms.html\n",
      "/2016/02/4223256228046kpauca1.jpg\n",
      "/ades_sevyds\n",
      "\n",
      "/thomo/midio-21_da0ea5dSdt-/C17/7a0aeet-2b0-16017008x67.jpg\n",
      "/es/radopenn-eiaris-mowasnex/973980-ioch-bley-iloie-pult/63066x-17.html\n",
      "/besdien-cratraviglen/bsice.html\n",
      "/remknip-skaaloy/porch_vgRors__E1d3f/e7%g%B6%D8%AA%D%D6%P0%D-%aC%D8%D0%15%81%93%/3\n",
      "/dindufoagiag\n",
      "/indec/yitse/2Anoes/356modecStepraarinos-tarf0aHRL/gpre/marelogxs/0s20140/4s/pataballa/malowwiy/vik-bua-532/yhetosur_xfnakunchuscagst-tles/54\n",
      "/colter-217/10/povs-talri.656_x36101104777\n",
      "/tictenter/pary/enni-coitgikhl20_tasiom.jpg.php\n",
      "/manp-po/dact24788815/t43c48.html\n",
      "/oumen/\n",
      "/contiht/115814.jpg\n",
      "/contpp/hefciptulo-ce-kezh-nbecks/1171.jpg\n",
      "/bouniner-ba__midar/_33921/mow/3s/terits/x/sost-4k39/alunne-tow-17439fx22Sw/01163607sf890/1/0/292/sosteldis/hrops/Neugy\n",
      "/contont/indymilem/\n",
      "/nevlalt/\n",
      "/chescyridie/parerin-tazenr-sara-bralilles-Bels/lenes-sraests/i/mijaryyytix/cmgg/talticna-tlogiaber/mpicleakinie/spoone/Shop_seofil-saantis/2/harcleluk-toen-kalan-ao-tastri/9.ostter\n",
      "/pros/nuwe-tioa-alrtorire-lartrar-dermasels/hondingulre-greey/20179.html\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/shzlbm-1c9shc-we-dlopacatew--ka.htm\n",
      "/elseseconubkslospolle-cric-gennes//eprosombo-homeloman-gida-tiges.html\n",
      "/folosticepcatazery-homraratene-chos-/5460-conteriayw-idpn-hadasermackay/letelion/seser/nston/gashmagfillnomaunustHonittSisi-ut/cat/ceden_inmloi/sarchationy/catearie-sarinc.jpg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/desce\n",
      "/log-categoro-s-adssefeme\n",
      " --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "temp = 1.0\n",
    "quote_length = 2000\n",
    "\n",
    "# pick random:\n",
    "start = random.randint(0, len(text_test) - unroll - 1)\n",
    "init_quote = text_test[start : start + unroll]\n",
    "\n",
    "generated = init_quote\n",
    "print('\\n', '-' * 50)\n",
    "print(\"Seed:\")\n",
    "sys.stdout.write(''.join([unichr(int(h, 16)) for h in init_quote]))\n",
    "print('\\n', '-' * 50)\n",
    "sys.stdout.write(''.join([unichr(int(h, 16)) for h in generated]))\n",
    "for i in range(quote_length):\n",
    "    x = np.zeros((1, unroll, 256))\n",
    "    for t,b in enumerate(generated):\n",
    "        x[0, t, byte_idx[b]] = 1.0\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, temperature=temp)\n",
    "    next_byte = hexabet[next_index]\n",
    "    generated = generated[1:] + [next_byte]\n",
    "\n",
    "    sys.stdout.write(unichr(int(next_byte, 16)))\n",
    "    sys.stdout.flush()\n",
    "print('\\n', '-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
